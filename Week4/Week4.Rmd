---
title: "Week 4 - Practical Machine Learning"
author: "Anyi Guo"
date: "30/12/2018"
output: pdf_document
---

# Week 4

## Regularized regression
### What is regularised regression?
1. Fit a regression model
2. Penalize (or shrink) large coefficients

**Pros**
1. Help with bias/variance tradeoff
2. Help with model selection

**Cons**
1. Computationally demanding
2. Lower performance than random forests and boosting 


Prediction error = irreducible error + bias^2 + variance

**Tuning parameter lambda**
1. lambda controls the size of the coefficients, and the amount of regularization 
2. As lambda approaches 0, we obtain the least squared solution (i.e. what we get from the standard linear model)

3. As lambda approaches infinity, the coefficients go towards 0

In `caret` methods for penalised regularization models are:
+ ridge
+ lasso
+ relaxo

## Combining predictors
1. Combining classifiers generally improves accuracy but reduces interpretability.

2. How? Use majority vote
* similar classifiers: bagging, boosting, random forest
* different classifiers: model stacking, model ensembling

3. example with wage data
```{r}
library(ISLR)
data(Wage)
library(ggplot2)
library(caret)
Wage<-subset(Wage,select=-c(logwage))

# Create a building data set (which is split into training and testing data) and validation set
inBuild<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
validation<-Wage[-inBuild,]
buildData<-Wage[inBuild,]

inTrain<-createDataPartition(y=buildData$wage,p=0.7,list=FALSE)
training<-buildData[inTrain,]
testing<-buildData[-inTrain,]

dim(training)
```

Build two different models: linear regression + random forest
```{r}
mod1<-train(wage~.,method="glm",data=training)
mod2<-train(wage~.,method="rf",data=training,trControl=trainControl(method="cv"),number=3)
```

Plot the two different models on the same chart
```{r}
pred1<-predict(mod1,testing)
pred2<-predict(mod2,testing)
qplot(pred1,pred2,colour=wage,data= testing)
```

#### Fit a model that combines two different predictors

First, create a new dataframe that is the prediction of the original two models. Then train a new model based on the new dataframe. 
```{r}
predDF<-data.frame(pred1,pred2,wage=testing$wage)
combModFit<-train(wage~.,method="gam",data=predDF)
combPred<-predict(combModFit,predDF)
```

#### Testing erros between the two original predictors and the combined predictor
```{r}
# linear regression
sqrt(sum((pred1-testing$wage)^2))

# random forest
sqrt(sum((pred2-testing$wage)^2))

# combined (linear regression + random forest)
sqrt(sum((combPred-testing$wage)^2))
```

We can see that the combined predictor has the lowest testing error rate

#### Predict on validation set
```{r}
pred1V<-predict(mod1,validation)
pred2V<-predict(mod2,validation)
predVDF<-data.frame(pred1=pred1V,pred2=pred2V)
combPredV<-predict(combModFit,predVDF)
```

#### Error rate on validation set
```{r}
# linear regression
sqrt(sum((pred1V-validation$wage)^2))
# random forest
sqrt(sum((pred2V-validation$wage)^2))
# combined 
sqrt(sum((combPredV-validation$wage)^2))

```

### Notes on combining predictors
Typical model for binary/multiclass data
* Build an odd number of models
* Predict with each model
* Predict the class by majority vote

## Forecasting on time series & spatial data
1. example: predict the price of Google stock 
```{r}
library(quantmod)
from.dat<-as.Date("01/01/08",format="%m/%d/%y")
to.dat<-as.Date("12/31/13",format="%m/%d/%y")
getSymbols("GOOG",src="yahoo",from=from.dat,to=to.dat)
```

#### Summarize monthly opening price for Google, and store it as time series
```{r}
mGoog<-to.monthly(GOOG)
googOpen<-Op(mGoog)
ts1<-ts(googOpen,frequency = 12)
plot(ts1,xlab="Year+1",ylab="GOOG")
```

#### Decompose a time series into parts
trend, seasonal and random 
```{r}
plot(decompose(ts1),xlab="Years+1")
```

#### Build training and test sets for the prediction
```{r}
ts1Train<-window(ts1,start=1,end=5)
ts1Test<-window(ts1,start=5,end=(7-0.01))
ts1Train
```

#### Simple moving average
```{r}
plot(ts1Train)
lines(ma(ts1Train,order=3),col="red")
```

#### Exponential smoothing (weights nearby time points more than points that are far away)

We can get a range of the possible 
```{r}
library(forecast)
ets1<-ets(ts1Train,model="MMM")
fcast<-forecast(ets1)
plot(fcast)
lines(ts1Test,col="red")
```

#### Get the accuracy of different exponential smoothing models

```{r}
accuracy(fcast,ts1Test)
```

Use `quantmod` and `quandl` packages for finance-related problems.

## Unsupervised Prediction

1. Sometimes you don't know the labels for prediction. 

2. To build a predictor, first:
* Create clusters
* Name clusters
* Build predictor for clusters

3. In a new data set, predict clusters

4. Example: Iris data set without species labels
```{r}
data(iris)
library(ggplot2)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
```

#### K-means clustering
```{r}
kMeans1<-kmeans(subset(training,select=-c(Species)),centers=3)
training$clusters<-as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,color=clusters,data=training)
```

#### Compare k-means clustering with real labels
```{r}
table(kMeans1$cluster,training$Species)
```

#### Build predictor after clustering, using classification tree
```{r}
modFit<-train(clusters~.,data=subset(training,select=-c(Species)),method="rpart")
table(predict(modFit,training),training$Species)
```

#### Apply the model on test dataset
```{r}
testClusterPred<-predict(modFit,testing)
table(testClusterPred,testing$Species)
```